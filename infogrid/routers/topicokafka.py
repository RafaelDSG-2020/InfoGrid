from fastapi import APIRouter, Depends, HTTPException
from http import HTTPStatus
from typing import List
import logging
from beanie import PydanticObjectId
from infogrid.models import TopicoKafka as TopicoKafkaModel, Usuario
from infogrid.database import get_db
from infogrid.schemas import TopicoKafka as TopicoKafkaSchema, TopicoKafkaPublic

logger = logging.getLogger("app_logger")

router = APIRouter(prefix="/api/v1/topicokafka", tags=["topicokafka"])


# ==========================
# LISTAR TODOS OS T√ìPICOS KAFKA
# ==========================

@router.get("/", status_code=HTTPStatus.OK, response_model=List[TopicoKafkaPublic])
async def list_topicos_kafka():
    """Lista todos os t√≥picos Kafka"""
    logger.info("Endpoint /topicokafka acessado")
    
    # Buscar os t√≥picos e carregar os links corretamente
    topicos = await TopicoKafkaModel.find(fetch_links=True).to_list(100)
    
    return [
        TopicoKafkaPublic(
            id=str(topico.id),
            nome=topico.nome,
            descricao=topico.descricao,
            responsaveis=[
                str(res.id) if hasattr(res, "id") else str(res) for res in topico.responsaveis
            ] if topico.responsaveis else [],
            estado_atual=topico.estado_atual,
            conformidade=topico.conformidade,
        )
        for topico in topicos
    ]


@router.get("/pagined/", status_code=HTTPStatus.OK, response_model=List[TopicoKafkaPublic])
async def list_topicos_kafka_paged(limit: int = 5, skip: int = 0):
    """Lista t√≥picos Kafka com pagina√ß√£o"""
    logger.info(f"Endpoint /topicokafka/pagined acessado com limite {limit} e offset {skip}")
    
    # Buscar os t√≥picos e carregar os links corretamente
    topicos = await TopicoKafkaModel.find(fetch_links=True).skip(skip).limit(limit).to_list()
    
    return [
        TopicoKafkaPublic(
            id=str(topico.id),
            nome=topico.nome,
            descricao=topico.descricao,
            responsaveis=[
                str(res.id) if hasattr(res, "id") else str(res) for res in topico.responsaveis
            ] if topico.responsaveis else [],
            estado_atual=topico.estado_atual,
            conformidade=topico.conformidade,
        )
        for topico in topicos
    ]


# ==========================
# CRIAR UM NOVO T√ìPICO KAFKA
# ==========================

@router.post("/", status_code=HTTPStatus.CREATED, response_model=TopicoKafkaPublic)
async def create_topico_kafka(topico: TopicoKafkaSchema, db=Depends(get_db)):
    """Cria um novo t√≥pico Kafka"""
    logger.info("Endpoint /topicokafka acessado para cria√ß√£o")

    # Converter IDs dos respons√°veis para PydanticObjectId
    responsaveis_ids = [PydanticObjectId(res_id) for res_id in topico.responsaveis]

    novo_topico = TopicoKafkaModel(
        nome=topico.nome,
        descricao=topico.descricao,
        responsaveis=responsaveis_ids,  # Armazena apenas os IDs
        estado_atual=topico.estado_atual,
        conformidade=topico.conformidade,
    )
    await novo_topico.insert()

    return TopicoKafkaPublic(
        id=str(novo_topico.id),
        nome=novo_topico.nome,
        descricao=novo_topico.descricao,
        responsaveis=[str(res) for res in novo_topico.responsaveis],  # Retorna os IDs como strings
        estado_atual=novo_topico.estado_atual,
        conformidade=novo_topico.conformidade,
    )



# ==========================
# DELETAR UM T√ìPICO KAFKA
# ==========================

@router.delete("/{topico_id}", status_code=HTTPStatus.NO_CONTENT)
async def delete_topico_kafka(topico_id: str):
    """Exclui um t√≥pico Kafka pelo ID"""
    logger.info(f"Tentativa de exclus√£o do t√≥pico Kafka com ID {topico_id}")

    db_topico = await TopicoKafkaModel.get(PydanticObjectId(topico_id))
    if not db_topico:
        logger.warning(f"T√≥pico Kafka com ID {topico_id} n√£o encontrado")
        raise HTTPException(status_code=HTTPStatus.NOT_FOUND, detail="T√≥pico Kafka not found")

    await db_topico.delete()

    logger.info(f"T√≥pico Kafka com ID {topico_id} exclu√≠do com sucesso")
    return {"message": "T√≥pico Kafka deleted successfully"}


# ==========================
# ATUALIZAR UM T√ìPICO KAFKA
# ==========================

@router.put("/{topico_id}", status_code=HTTPStatus.OK, response_model=TopicoKafkaPublic)
async def update_topico_kafka(topico_id: str, topico: TopicoKafkaSchema):
    """Atualiza um t√≥pico Kafka pelo ID"""
    logger.info(f"Tentativa de atualiza√ß√£o do t√≥pico Kafka com ID {topico_id}")

    # Buscar o t√≥pico no banco de dados
    db_topico = await TopicoKafkaModel.get(PydanticObjectId(topico_id), fetch_links=True)
    if not db_topico:
        logger.warning(f"T√≥pico Kafka com ID {topico_id} n√£o encontrado")
        raise HTTPException(status_code=HTTPStatus.NOT_FOUND, detail="T√≥pico Kafka not found")

    # Atualizar respons√°veis corretamente
    if topico.responsaveis:
        responsaveis_links = [PydanticObjectId(res_id) for res_id in topico.responsaveis]
    else:
        responsaveis_links = db_topico.responsaveis  # Mant√©m os respons√°veis existentes

    # Criar dicion√°rio de atualiza√ß√£o apenas com os campos preenchidos
    update_data = {
        "nome": topico.nome if topico.nome else db_topico.nome,
        "descricao": topico.descricao if topico.descricao else db_topico.descricao,
        "responsaveis": responsaveis_links,
        "estado_atual": topico.estado_atual if topico.estado_atual else db_topico.estado_atual,
        "conformidade": topico.conformidade if topico.conformidade is not None else db_topico.conformidade,
    }

    # Aplicar a atualiza√ß√£o no banco
    await db_topico.set(update_data)

    logger.info(f"T√≥pico Kafka com ID {topico_id} atualizado com sucesso")

    # Retornar o objeto atualizado corretamente formatado
    return TopicoKafkaPublic(
        id=str(db_topico.id),
        nome=db_topico.nome,
        descricao=db_topico.descricao,
        responsaveis=[str(res.id) if hasattr(res, "id") else str(res) for res in db_topico.responsaveis] if db_topico.responsaveis else [],
        estado_atual=db_topico.estado_atual,
        conformidade=db_topico.conformidade,
    )



# ==========================
# CONTAR T√ìPICOS KAFKA
# ==========================

@router.get("/count", status_code=HTTPStatus.OK)
async def count_topicos_kafka():
    """Conta o n√∫mero total de t√≥picos Kafka"""
    logger.info("Endpoint /topicokafka/count acessado")
    quantidade = await TopicoKafkaModel.find().count()
    logger.info(f"Quantidade de t√≥picos Kafka: {quantidade}")
    return {"quantidade": quantidade}


from bson import ObjectId, DBRef

@router.get("/with-columns-responsaveis/", status_code=HTTPStatus.OK)
async def list_kafka_topics_with_columns_and_responsaveis():
    """Lista T√≥picos Kafka, suas Colunas associadas e Respons√°veis usando agrega√ß√£o"""
    logger.info("Endpoint /api/v1/kafka/with-columns-responsaveis acessado")

    pipeline = [
        {
            "$lookup": {
                "from": "ColunaTopicoKafka",  # üîπ Nome correto da cole√ß√£o
                "localField": "_id",  # ‚úÖ Correto, pois '_id' √© um ObjectId no TopicoKafka
                "foreignField": "topico_kafka.$id",  # ‚úÖ Agora resolve DBRef corretamente
                "as": "colunas"
            }
        },
        {
            "$lookup": {
                "from": "Responsavel",  # üîπ Associando respons√°veis corretamente
                "localField": "responsaveis.$id",  # ‚úÖ Correto para resolver DBRef
                "foreignField": "_id",
                "as": "responsaveis"
            }
        },
        {
            "$project": {  # üîπ Organizando a estrutura final da resposta
                "_id": 1,
                "nome": 1,
                "descricao": 1,
                "estado_atual": 1,
                "conformidade": 1,
                "responsaveis": 1,
                "colunas": {
                    "$map": {
                        "input": "$colunas",
                        "as": "col",
                        "in": {
                            "_id": "$$col._id",
                            "nome": "$$col.nome",
                            "tipo_dado": "$$col.tipo_dado",
                            "descricao": "$$col.descricao"
                        }
                    }
                }  # üîπ Remove o campo "topico_kafka" das colunas
            }
        }
    ]

    result = await TopicoKafkaModel.aggregate(pipeline).to_list(100)

    if not result:
        raise HTTPException(status_code=HTTPStatus.NOT_FOUND, detail="Nenhum T√≥pico Kafka encontrado")

    # ‚úÖ Converte ObjectId para string
    def clean_objectid_dbref(obj):
        """Converte ObjectId para string e remove DBRef."""
        if isinstance(obj, ObjectId):
            return str(obj)  # Converte ObjectId para string
        if isinstance(obj, DBRef):
            return str(obj.id)  # Extrai apenas o ObjectId do DBRef
        if isinstance(obj, dict):
            return {k: clean_objectid_dbref(v) for k, v in obj.items()}  # Converte recursivamente
        if isinstance(obj, list):
            return [clean_objectid_dbref(v) for v in obj]  # Converte listas recursivamente
        return obj

    result = clean_objectid_dbref(result)

    return result

@router.get("/topico-kafka/{topico_id}", status_code=HTTPStatus.OK)
async def get_topico_kafka_by_id(topico_id: str):
    """Busca um T√≥pico Kafka pelo ID"""
    topico = await TopicoKafkaModel.get(PydanticObjectId(topico_id))
    if not topico:
        raise HTTPException(status_code=HTTPStatus.NOT_FOUND, detail="T√≥pico Kafka n√£o encontrado")
    return topico
